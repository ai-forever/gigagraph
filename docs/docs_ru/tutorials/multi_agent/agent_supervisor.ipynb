{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
         "metadata": {},
         "source": [
            "## Руководитель агентов\n",
            "\n",
            "В [предыдущем примере](multi-agent-collaboration.ipynb) вы можете ознакомиться с автоматической маршрутизацией сообщений в зависимости от результата работы первичного агента-исследователя.\n",
            "\n",
            "Кроме такого подхода вы можете использовать LLM для организации работы агентов.\n",
            "\n",
            "Пример ниже показывает как создать группу агентов с LLM в роли руководителя, который помогает распределять задачи.\n",
            "\n",
            "![Схема](./img/supervisor-diagram.png)\n",
            "\n",
            "Для упрощения кода каждой из вершин, в которых распологаются агенты, используется класс `AgentExecutor` библиотеки LangChain. Таким образом этот и другие сложные примеры показывают различные подходы к проектированию с помощью LangGraph. Комбинируйте эти подходы с другими базовыми решениями, для более эффективного решения своих задач. \n",
            "\n",
            "Перед началом разработки подготовьте среду:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
         "metadata": {},
         "outputs": [],
         "source": [
            "%%capture --no-stderr\n%pip install -U langgraph langchain langchain_openai langchain_experimental langsmith pandas"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
         "metadata": {},
         "outputs": [],
         "source": [
            "import getpass\nimport os\n\n\ndef _set_if_undefined(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n\n\n_set_if_undefined(\"OPENAI_API_KEY\")\n_set_if_undefined(\"LANGCHAIN_API_KEY\")\n_set_if_undefined(\"TAVILY_API_KEY\")\n\n# Optional, add tracing in LangSmith\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-agent Collaboration\""
         ]
      },
      {
         "cell_type": "markdown",
         "id": "1ac25624-4d83-45a4-b9ef-a10589aacfb7",
         "metadata": {},
         "source": [
            "## Создание инструментов\n",
            "\n",
            "Для этого примера вам потребуется два агента. Первый будет выполнять исследование с помощью запросов к поисковой системе, а второй будет отрисовывать графики.\n",
            "\n",
            "Задайте инструменты, которые будут использовать каждый из агентов:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "f04c6778-403b-4b49-9b93-678e910d5cec",
         "metadata": {},
         "outputs": [],
         "source": [
            "from typing import Annotated\n",
            "\n",
            "from langchain_community.tools.tavily_search import TavilySearchResults\n",
            "from langchain_experimental.tools import PythonREPLTool\n",
            "\n",
            "tavily_tool = TavilySearchResults(max_results=5)\n",
            "\n",
            "# Функция выполняет код локально, что может быть небезсопасно\n",
            "python_repl_tool = PythonREPLTool()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d58d1e85-22d4-4c22-9062-72a346a0d709",
         "metadata": {},
         "source": [
            "## Создание вспомогательных функций\n",
            "\n",
            "Создайте вспомогательную функцию, которая упростит добавление вершин с агентами-исполнителями:"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "c4823dd9-26bd-4e1a-8117-b97b2860211a",
         "metadata": {},
         "outputs": [],
         "source": [
            "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
            "from langchain_core.messages import BaseMessage, HumanMessage\n",
            "from langchain_openai import ChatOpenAI\n",
            "\n",
            "\n",
            "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
            "    # Каждой вершине с исполнителем присваивается имя и дается доступ\n",
            "    # к определенным инструментам\n",
            "    prompt = ChatPromptTemplate.from_messages(\n",
            "        [\n",
            "            (\n",
            "                \"system\",\n",
            "                system_prompt,\n",
            "            ),\n",
            "            MessagesPlaceholder(variable_name=\"messages\"),\n",
            "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
            "        ]\n",
            "    )\n",
            "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
            "    executor = AgentExecutor(agent=agent, tools=tools)\n",
            "    return executor"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "b7c302b0-cd57-4913-986f-5dc7d6d77386",
         "metadata": {},
         "source": [
            "Также определите функцию, которая будет представлять вершины графа. Функция будет преобразовывать ответ агента в сообщения от человека (`HumanMessage`). Это нужно для работы с глобальным состоянием графа."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "80862241-a1a7-4726-bce5-f867b233832e",
         "metadata": {},
         "outputs": [],
         "source": [
            "def agent_node(state, agent, name):\n    result = agent.invoke(state)\n    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d32962d2-5487-496d-aefc-2a3b0d194985",
         "metadata": {},
         "source": [
            "### Создайте руководителя агентов\n",
            "\n",
            "Руководитель вызывает функцию, чтобы определенить следующую вершину-исполнителя или завершить обработку."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "311f0a58-b425-4496-adac-dc4cd8ffb912",
         "metadata": {},
         "outputs": [],
         "source": [
            "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
            "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
            "\n",
            "members = [\"Researcher\", \"Coder\"]\n",
            "system_prompt = (\n",
            "    \"Вы - руководитель, задача которого заключается в управлении разговором между\"\n",
            "    \" следующими сотрудниками: {members}. Учитывая следующий запрос пользователя,\"\n",
            "    \" ответьте, какой сотрудник должен действовать далее. Каждый сотрудник будет выполнять\"\n",
            "    \" задачу и отвечать своими результатами и статусом. Когда работа будет завершена,\"\n",
            "    \" ответьте FINISH.\"\n",
            ")\n",
            "# Руководитель агентов — это LLM-вершина графа. Руководитель определяет\n",
            "# какому из агентов передать задачу и принимает решение о ее выполнении\n",
            "options = [\"FINISH\"] + members\n",
            "# Использование openai-функций упрощает обработку вывода\n",
            "function_def = {\n",
            "    \"name\": \"route\",\n",
            "    \"description\": \"Select the next role.\",\n",
            "    \"parameters\": {\n",
            "        \"title\": \"routeSchema\",\n",
            "        \"type\": \"object\",\n",
            "        \"properties\": {\n",
            "            \"next\": {\n",
            "                \"title\": \"Next\",\n",
            "                \"anyOf\": [\n",
            "                    {\"enum\": options},\n",
            "                ],\n",
            "            }\n",
            "        },\n",
            "        \"required\": [\"next\"],\n",
            "    },\n",
            "}\n",
            "prompt = ChatPromptTemplate.from_messages(\n",
            "    [\n",
            "        (\"system\", system_prompt),\n",
            "        MessagesPlaceholder(variable_name=\"messages\"),\n",
            "        (\n",
            "            \"system\",\n",
            "            \"Исходя из приведенного выше разговора, кто должен действовать дальше?\"\n",
            "            \" Или мы должны завершить? Выберите один из: {options}\",\n",
            "        )\n",
            "    ]\n",
            ").partial(options=str(options), members=\", \".join(members))\n",
            "\n",
            "llm = ChatOpenAI(model=\"gpt-4-1106-preview\")\n",
            "\n",
            "supervisor_chain = (\n",
            "    prompt\n",
            "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
            "    | JsonOutputFunctionsParser()\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "a07d507f-34d1-4f1b-8dde-5e58d17b2166",
         "metadata": {},
         "source": [
            "## Соберите граф\n",
            "\n",
            "Теперь вы можете собрать граф.\n",
            "Для этого определите состояние агента и вершины-исполнители. Для определения вершин используйте созданную вспомогательную функцию."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "6a430af7-8fce-4e66-ba9e-d940c1bc48e8",
         "metadata": {},
         "outputs": [],
         "source": [
            "import functools\n",
            "import operator\n",
            "from typing import Sequence, TypedDict\n",
            "\n",
            "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
            "\n",
            "from langgraph.graph import END, StateGraph\n",
            "\n",
            "\n",
            "# Состояние агента передается на вход каждой из вершин графа\n",
            "class AgentState(TypedDict):\n",
            "    # Аннотация указывает графу, что новые сообщения нужно всегда\n",
            "    # добавлять к текущим состояниям\n",
            "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
            "    # Поле 'next' указывает, что делать дальше\n",
            "    next: str\n",
            "\n",
            "\n",
            "research_agent = create_agent(llm, [tavily_tool], \"Ты аналитик, который ищет информацию и обрабатывает результаты\")\n",
            "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
            "\n",
            "# NOTE: НА ЭТОМ ЭТАПЕ ВЫПОЛНЯЕТСЯ ПРОИЗВОЛЬНЫЙ КОД. БУДЬТЕ ОСТОРОЖНЫ\n",
            "code_agent = create_agent(\n",
            "    llm,\n",
            "    [python_repl_tool],\n",
            "    \"Вы можете генерировать безопасный код на Python для анализа данных и создания графиков с использованием matplotlib.\",\n",
            ")\n",
            "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
            "\n",
            "workflow = StateGraph(AgentState)\n",
            "workflow.add_node(\"Researcher\", research_node)\n",
            "workflow.add_node(\"Coder\", code_node)\n",
            "workflow.add_node(\"supervisor\", supervisor_chain)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "2c1593d5-39f7-4819-96d2-4ad7d7991d72",
         "metadata": {},
         "source": [
            "Соедините все ребра графа."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "14778e86-077b-4e6a-893c-400e59b0cdbf",
         "metadata": {},
         "outputs": [],
         "source": [
            "for member in members:\n",
            "    # Исполнители должны ВСЕГДА докладывать руководителю о завершении работы\n",
            "    workflow.add_edge(member, \"supervisor\")\n",
            "# Руководитель заполняет поле \"next\" в состостоянии графа,\n",
            "# которое переходит к другой вершине или заканчивает обработку\n",
            "conditional_map = {k: k for k in members}\n",
            "conditional_map[\"FINISH\"] = END\n",
            "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
            "# Добавьте точку входа\n",
            "workflow.set_entry_point(\"supervisor\")\n",
            "\n",
            "graph = workflow.compile()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "d36496de-7121-4c49-8cb6-58c943c66628",
         "metadata": {},
         "source": [
            "## Запустите граф\n",
            "\n",
            "Теперь, когда граф собран, вы можете запустить его и посмотреть, как он работает."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'supervisor': {'next': 'Coder'}}\n",
                  "----\n",
                  "{'Coder': {'messages': [HumanMessage(content='Факториал числа 15 равен 1,307,674,368,000.', name='Coder')]}}\n",
                  "----\n",
                  "{'supervisor': {'next': 'Coder'}}\n",
                  "----\n",
                  "{'Coder': {'messages': [HumanMessage(content='Функция для вычисления факториала числа была успешно выполнена, и факториал числа 15 равен 1,307,674,368,000.', name='Coder')]}}\n",
                  "----\n",
                  "{'supervisor': {'next': 'FINISH'}}\n",
                  "----\n"
               ]
            }
         ],
         "source": [
            "for s in graph.stream(\n",
            "    {\n",
            "        \"messages\": [\n",
            "            HumanMessage(content=\"Напиши на python функцию для вычисления факториала и найди факториал числа 15.\")\n",
            "        ]\n",
            "    }\n",
            "):\n",
            "    if \"__end__\" not in s:\n",
            "        print(s)\n",
            "        print(\"----\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "id": "45a92dfd-0e11-47f5-aad4-b68d24990e34",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'supervisor': {'next': 'Researcher'}}\n",
                  "----\n",
                  "{'Researcher': {'messages': [HumanMessage(content='Илон Маск подал иск против OpenAI и её генерального директора Сэма Альтмана. Основные обвинения касаются нарушения договора, при котором компания, по словам Маска, отошла от своей первоначальной миссии как некоммерческой организации. Маск утверждает, что OpenAI ушла от принципа открытости, партнерствуя с Microsoft на 13 миллиардов долларов и сохраняя в тайне код своих новейших продуктов в области генеративного искусства.\\n\\nOpenAI была соучредителем Илона Маска в 2015 году, но с тех пор он покинул компанию и основал свою собственную компанию в области искусственного интеллекта, xAI. В иске упоминается, что Microsoft, которая вложила миллиарды долларов в OpenAI и имеет тесное партнерство с стартапом, не является ответчиком, но упоминается в жалобе 68 раз.\\n\\nМаск обвиняет OpenAI и Сэма Альтмана в том, что они ставят прибыль и коммерческие интересы в разработке искусственного интеллекта выше общественного блага, отступая от исходных принципов компании. Иск подчеркивает нерешенные вопросы в сообществе ИИ, такие как улучшит ли искусственный интеллект мир или уничтожит его и должен ли он быть строго контролируемым или освобожденным.', name='Researcher')]}}\n",
                  "----\n",
                  "{'supervisor': {'next': 'FINISH'}}\n",
                  "----\n"
               ]
            }
         ],
         "source": [
            "for s in graph.stream(\n",
            "    {\"messages\": [HumanMessage(content=\"Напиши краткий отчет о том, за что Илон Маск подал в суд на OpenAI\")]},\n",
            "    {\"recursion_limit\": 100},\n",
            "):\n",
            "    if \"__end__\" not in s:\n",
            "        print(s)\n",
            "        print(\"----\")"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.13"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
